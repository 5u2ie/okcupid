{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from utils.calculate_pmi_features import get_data\n",
    "from utils.textnormalization import split_on_word, normalize\n",
    "from utils.happyfuntokenizing import Tokenizer\n",
    "from utils.nonnegative_matrix_factorization import nmf_inspect, nmf_labels\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.rc('savefig', dpi=200)\n",
    "params = {'figure.dpi' : 200,\n",
    "          'axes.axisbelow' : True,\n",
    "          'lines.antialiased' : True}\n",
    "\n",
    "for (k, v) in params.items():\n",
    "    plt.rcParams[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences(s_list):\n",
    "    words = split_on_word(s_list)\n",
    "    words_norm = normalize(words)\n",
    "    return [' '.join(s) for s in words_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "essays = ['essay' + str(i) for i in range(10)]\n",
    "for e in essays:\n",
    "    df[e] = df[e].replace(np.nan, '' , regex=True)    \\\n",
    "                 .replace('\\n', ' ')                  \\\n",
    "                 .apply(lambda x: TAG_RE.sub(' ', x)) \\\n",
    "                 .apply(lambda x: re.sub('\\s+', ' ', x).strip())\n",
    "\n",
    "df.fillna('', inplace=True)\n",
    "df['ethnicity_'] = df.ethnicity.apply(lambda x: 'multi' if ',' in x else x)\n",
    "df['token_count'] = df.TotalEssays.str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_token_threshold = df[df.token_count >= 100]\n",
    "df_token_threshold.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay = 'essay4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = sentences(df_token_threshold[essay].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english',\n",
    "                        tokenizer=Tokenizer().tokenize,\n",
    "                        sublinear_tf=True,\n",
    "                        min_df=0.01, max_df=0.5)\n",
    "data = tfidf.fit_transform(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Group 0:\n",
      "favorite love movie book italian mexican rock thai hop hip\n",
      "\n",
      "Group 1:\n",
      "like i'm read don't love really good watch lot ...\n",
      "\n",
      "Group 2:\n",
      "books amp shows ... men dead black big game family\n",
      "\n",
      "\n",
      "5\n",
      "Group 0:\n",
      "like i'm read don't really love watch good lot reading\n",
      "\n",
      "Group 1:\n",
      "books shows men amp dead black game big family bad\n",
      "\n",
      "Group 2:\n",
      "... .... list know love yes books ask goes say\n",
      "\n",
      "Group 3:\n",
      "love italian rock mexican thai hop hip jazz amp indian\n",
      "\n",
      "Group 4:\n",
      "favorite movie book time love shows include band foods probably\n",
      "\n",
      "\n",
      "7\n",
      "Group 0:\n",
      "like i'm read don't really lot watch good i've reading\n",
      "\n",
      "Group 1:\n",
      "books shows men amp dead black game big family bad\n",
      "\n",
      "Group 2:\n",
      "rock italian mexican thai hop indian hip amp jazz chinese\n",
      "\n",
      "Group 3:\n",
      "... .... know yes books say good ..... little ask\n",
      "\n",
      "Group 4:\n",
      "love kinds new types eat cook live books good enjoy\n",
      "\n",
      "Group 5:\n",
      "list long way goes ask i'll favorites .... things far\n",
      "\n",
      "Group 6:\n",
      "favorite movie book time shows include band foods probably series\n",
      "\n",
      "\n",
      "9\n",
      "Group 0:\n",
      "like i'm really good reading it's things i've pretty enjoy\n",
      "\n",
      "Group 1:\n",
      "amp black david john life man radiohead books club sunshine\n",
      "\n",
      "Group 2:\n",
      "love kinds types new eat enjoy live cook books good\n",
      "\n",
      "Group 3:\n",
      "italian thai mexican indian chinese japanese sushi vietnamese french korean\n",
      "\n",
      "Group 4:\n",
      "rock hop hip amp jazz country classic classical rap pop\n",
      "\n",
      "Group 5:\n",
      "favorite movie book time include band foods probably say author\n",
      "\n",
      "Group 6:\n",
      "shows family game modern thrones men harry books met potter\n",
      "\n",
      "Group 7:\n",
      "read watch don't lot listen books time fiction eat recently\n",
      "\n",
      "Group 8:\n",
      "... .... list know books yes ask goes say long\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmf_inspect(data, tfidf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = nmf_labels(data, n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 0, ..., 3, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_token_threshold['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Token Count by Cluster (Topic)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    428.523290\n",
       "1    489.737341\n",
       "2    365.301708\n",
       "3    374.756663\n",
       "4    370.328346\n",
       "5    347.436265\n",
       "6    368.591274\n",
       "7    410.525881\n",
       "8    365.706466\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Average Token Count by Cluster (Topic)')\n",
    "df_token_threshold.groupby('labels')['token_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Samples by Cluster (Topic)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    13761\n",
       "1    11810\n",
       "2     4859\n",
       "3     3452\n",
       "4     3609\n",
       "5     3491\n",
       "6     5226\n",
       "7     2299\n",
       "8     2320\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Distribution of Samples by Cluster (Topic)')\n",
    "pd.DataFrame(labels)[0].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
